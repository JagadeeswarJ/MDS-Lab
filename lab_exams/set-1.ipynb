{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37962ce",
   "metadata": {},
   "source": "# Lab Exam - Set 1\n\nThis notebook contains implementations for all questions in Set 1."
  },
  {
   "cell_type": "markdown",
   "id": "6oc5pwfkiq5",
   "source": "## Question 1: NumPy Arrays - Creation, Reshaping, and Joining\n\n**Concepts:**\n- **NumPy**: Python library for numerical computing with arrays\n- **Intrinsic objects**: Built-in NumPy functions like `arange()`, `zeros()`, `ones()`\n- **Random functions**: Functions to generate random numbers\n- **Reshaping**: Changing array dimensions without changing data\n- **Joining**: Combining multiple arrays (concatenate, stack, etc.)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "zg5jgdajfag",
   "source": "import numpy as np\n\n# Creating arrays using intrinsic objects\narr1 = np.arange(12)  # Array from 0 to 11\narr2 = np.zeros((3, 4))  # 3x4 array of zeros\narr3 = np.ones((2, 6))  # 2x6 array of ones\n\n# Creating arrays using random functions\narr4 = np.random.randint(0, 100, size=12)  # Random integers\narr5 = np.random.rand(3, 4)  # Random floats between 0 and 1\n\nprint(\"Array 1 (arange):\", arr1)\nprint(\"\\nArray 2 (zeros):\\n\", arr2)\nprint(\"\\nArray 4 (random integers):\", arr4)\n\n# Reshaping operations\nreshaped1 = arr1.reshape(3, 4)  # Convert 1D to 3x4\nreshaped2 = arr4.reshape(4, 3)  # Convert 1D to 4x3\nprint(\"\\nReshaped arr1 to 3x4:\\n\", reshaped1)\nprint(\"\\nReshaped arr4 to 4x3:\\n\", reshaped2)\n\n# Joining operations\n# Concatenate along axis 0 (rows)\nconcat_vertical = np.concatenate([reshaped1, arr2], axis=0)\nprint(\"\\nVertical concatenation (6x4):\\n\", concat_vertical)\n\n# Stack arrays horizontally\nhstack_result = np.hstack([reshaped1, arr5])\nprint(\"\\nHorizontal stack (3x8):\\n\", hstack_result)\n\n# Vertical stack\nvstack_result = np.vstack([reshaped1, arr2])\nprint(\"\\nVertical stack (6x4):\\n\", vstack_result)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "wjtwzy3xi5a",
   "source": "## Question 2: Pandas DataFrame - CSV Import and Data Cleaning\n\n**Concepts:**\n- **DataFrame**: 2D labeled data structure in Pandas (like Excel table)\n- **Missing values**: Empty or null entries in data (handled with `fillna()`, `dropna()`)\n- **Outliers**: Data points significantly different from others (detected using IQR method)\n- **Statistical summaries**: Mean, median, standard deviation, etc. using `describe()`\n- **IQR (Interquartile Range)**: Q3 - Q1, used to find outliers",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "0rc2hvpn8afp",
   "source": "import pandas as pd\nimport numpy as np\n\n# Create a sample CSV file for demonstration\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Henry'],\n    'Age': [25, 30, np.nan, 28, 35, 22, 150, 29],  # 150 is outlier, one missing\n    'Salary': [50000, 60000, 55000, np.nan, 70000, 48000, 62000, 200000],  # 200000 outlier\n    'Score': [85, 90, 78, 88, np.nan, 92, 87, 89]\n}\ndf_sample = pd.DataFrame(data)\ndf_sample.to_csv('sample_data.csv', index=False)\n\n# Import CSV file\ndf = pd.read_csv('sample_data.csv')\nprint(\"Original DataFrame:\")\nprint(df)\n\n# Handle missing values\nprint(\"\\n\\nMissing values count:\")\nprint(df.isnull().sum())\n\n# Fill missing values with mean for numeric columns\ndf['Age'].fillna(df['Age'].mean(), inplace=True)\ndf['Salary'].fillna(df['Salary'].median(), inplace=True)\ndf['Score'].fillna(df['Score'].mean(), inplace=True)\n\nprint(\"\\n\\nDataFrame after handling missing values:\")\nprint(df)\n\n# Detect outliers using IQR method\ndef detect_outliers_iqr(df, column):\n    Q1 = df[column].quantile(0.25)\n    Q3 = df[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n    return outliers, lower_bound, upper_bound\n\nprint(\"\\n\\nOutlier Detection:\")\nfor col in ['Age', 'Salary', 'Score']:\n    outliers, lower, upper = detect_outliers_iqr(df, col)\n    print(f\"\\n{col} - Bounds: [{lower:.2f}, {upper:.2f}]\")\n    if not outliers.empty:\n        print(f\"Outliers found:\\n{outliers[['Name', col]]}\")\n    else:\n        print(\"No outliers found\")\n\n# Statistical summaries\nprint(\"\\n\\nStatistical Summary:\")\nprint(df.describe())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "szxgblva5ma",
   "source": "## Question 3: Data Visualization - Histograms and Density Plots\n\n**Concepts:**\n- **Histogram**: Bar chart showing frequency distribution of data\n- **Density plot (KDE)**: Smooth curve showing probability distribution\n- **Distribution patterns**: Shape of data (normal, skewed, bimodal, etc.)\n- **Matplotlib**: Python library for creating visualizations",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "5zbes5hsh0i",
   "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Use the dataframe from previous question\n# Plot histograms and density plots for numeric columns\nnumeric_cols = ['Age', 'Salary', 'Score']\n\nfig, axes = plt.subplots(3, 2, figsize=(12, 10))\nfig.suptitle('Distribution Analysis - Histograms and Density Plots', fontsize=16)\n\nfor idx, col in enumerate(numeric_cols):\n    # Histogram\n    axes[idx, 0].hist(df[col], bins=10, color='skyblue', edgecolor='black', alpha=0.7)\n    axes[idx, 0].set_title(f'{col} - Histogram')\n    axes[idx, 0].set_xlabel(col)\n    axes[idx, 0].set_ylabel('Frequency')\n    axes[idx, 0].grid(True, alpha=0.3)\n    \n    # Density plot (KDE)\n    df[col].plot(kind='density', ax=axes[idx, 1], color='coral', linewidth=2)\n    axes[idx, 1].set_title(f'{col} - Density Plot')\n    axes[idx, 1].set_xlabel(col)\n    axes[idx, 1].set_ylabel('Density')\n    axes[idx, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Additional: Combined histogram with density plot\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\nfor idx, col in enumerate(numeric_cols):\n    axes[idx].hist(df[col], bins=10, density=True, alpha=0.6, color='skyblue', edgecolor='black')\n    df[col].plot(kind='density', ax=axes[idx], color='red', linewidth=2)\n    axes[idx].set_title(f'{col} Distribution')\n    axes[idx].set_xlabel(col)\n    axes[idx].legend(['Density', 'Histogram'])\n    axes[idx].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "vg0u5reguym",
   "source": "## Question 4: K-Nearest Neighbors (KNN) Classifier on Iris Dataset\n\n**Concepts:**\n- **KNN**: Supervised learning algorithm that classifies based on nearest neighbors\n- **Iris dataset**: Famous dataset with 3 flower species and 4 features\n- **Train-test split**: Dividing data into training and testing sets\n- **Confusion matrix**: Table showing correct vs incorrect predictions\n- **Accuracy**: Percentage of correct predictions",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "cu7b2mlfpt",
   "source": "from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport seaborn as sns\n\n# Load Iris dataset\niris = load_iris()\nX = iris.data  # Features: sepal length, sepal width, petal length, petal width\ny = iris.target  # Target: 0=setosa, 1=versicolor, 2=virginica\n\nprint(\"Dataset shape:\", X.shape)\nprint(\"Classes:\", iris.target_names)\nprint(\"\\nFirst 5 samples:\")\nprint(X[:5])\n\n# Split dataset into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"\\nTraining set size: {X_train.shape[0]}\")\nprint(f\"Testing set size: {X_test.shape[0]}\")\n\n# Create and train KNN classifier (k=3)\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\n\n# Make predictions\ny_pred = knn.predict(X_test)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"\\n\\nAccuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(\"\\nConfusion Matrix:\")\nprint(cm)\n\n# Visualize confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=iris.target_names, \n            yticklabels=iris.target_names)\nplt.title('Confusion Matrix - KNN Classifier')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()\n\n# Classification Report\nprint(\"\\n\\nClassification Report:\")\nprint(classification_report(y_test, y_pred, target_names=iris.target_names))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}