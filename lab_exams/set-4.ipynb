{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Exam - Set 4\n",
    "\n",
    "This notebook contains implementations for all questions in Set 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13: Outlier Detection and Treatment using IQR Method\n",
    "\n",
    "**Concepts:**\n",
    "- **Outliers**: Data points that are significantly different from other observations\n",
    "- **IQR (Interquartile Range)**: Q3 - Q1, measures statistical dispersion\n",
    "- **Q1 (First Quartile)**: 25th percentile of data\n",
    "- **Q3 (Third Quartile)**: 75th percentile of data\n",
    "- **Outlier bounds**: Values outside [Q1 - 1.5×IQR, Q3 + 1.5×IQR] are outliers\n",
    "- **Median replacement**: Replace extreme values with median (robust to outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a sample dataset with outliers\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Student_ID': range(1, 51),\n",
    "    'Math_Score': np.random.normal(75, 10, 50),\n",
    "    'Science_Score': np.random.normal(80, 12, 50),\n",
    "    'English_Score': np.random.normal(70, 8, 50),\n",
    "    'Study_Hours': np.random.normal(5, 1.5, 50)\n",
    "}\n",
    "\n",
    "# Add some intentional outliers\n",
    "data['Math_Score'][5] = 150  # Extreme outlier\n",
    "data['Math_Score'][10] = 10  # Extreme outlier\n",
    "data['Science_Score'][15] = 200  # Extreme outlier\n",
    "data['Study_Hours'][20] = 15  # Outlier\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Dataset:\")\n",
    "print(df.head(10))\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Function to detect outliers using IQR method\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"\n",
    "    Detect outliers in a column using IQR method\n",
    "    Returns: outliers dataframe, lower bound, upper bound\n",
    "    \"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Calculate bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Find outliers\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    \n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Function to replace outliers with median\n",
    "def replace_outliers_with_median(data, column):\n",
    "    \"\"\"\n",
    "    Replace outliers in a column with the median value\n",
    "    Returns: cleaned column\n",
    "    \"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Calculate median\n",
    "    median_value = data[column].median()\n",
    "    \n",
    "    # Replace outliers with median\n",
    "    cleaned_column = data[column].copy()\n",
    "    cleaned_column[(cleaned_column < lower_bound) | (cleaned_column > upper_bound)] = median_value\n",
    "    \n",
    "    return cleaned_column\n",
    "\n",
    "# Detect outliers in all numeric columns\n",
    "numeric_columns = ['Math_Score', 'Science_Score', 'English_Score', 'Study_Hours']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OUTLIER DETECTION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in numeric_columns:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Lower Bound: {lower:.2f}\")\n",
    "    print(f\"  Upper Bound: {upper:.2f}\")\n",
    "    \n",
    "    if not outliers.empty:\n",
    "        print(f\"  Outliers Found: {len(outliers)}\")\n",
    "        print(f\"  Outlier Values: {outliers[col].values}\")\n",
    "    else:\n",
    "        print(\"  No outliers found\")\n",
    "\n",
    "# Create a copy of dataframe for cleaning\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Replace outliers with median for all numeric columns\n",
    "for col in numeric_columns:\n",
    "    df_cleaned[col] = replace_outliers_with_median(df, col)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AFTER REPLACING OUTLIERS WITH MEDIAN\")\n",
    "print(\"=\"*80)\n",
    "print(df_cleaned.describe())\n",
    "\n",
    "# Visualize before and after comparison\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('Outlier Detection and Treatment using IQR Method', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, col in enumerate(numeric_columns):\n",
    "    # Before - Box plot\n",
    "    axes[0, idx].boxplot(df[col], vert=True)\n",
    "    axes[0, idx].set_title(f'{col}\\n(Before Treatment)', fontweight='bold')\n",
    "    axes[0, idx].set_ylabel('Value')\n",
    "    axes[0, idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # After - Box plot\n",
    "    axes[1, idx].boxplot(df_cleaned[col], vert=True)\n",
    "    axes[1, idx].set_title(f'{col}\\n(After Treatment)', fontweight='bold')\n",
    "    axes[1, idx].set_ylabel('Value')\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON OF STATISTICS (Before vs After)\")\n",
    "print(\"=\"*80)\n",
    "for col in numeric_columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean: {df[col].mean():.2f} → {df_cleaned[col].mean():.2f}\")\n",
    "    print(f\"  Std Dev: {df[col].std():.2f} → {df_cleaned[col].std():.2f}\")\n",
    "    print(f\"  Min: {df[col].min():.2f} → {df_cleaned[col].min():.2f}\")\n",
    "    print(f\"  Max: {df[col].max():.2f} → {df_cleaned[col].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14: Correlation and Feature Importance Analysis\n",
    "\n",
    "**Concepts:**\n",
    "- **Correlation**: Measure of relationship between two variables (-1 to +1)\n",
    "- **Positive correlation**: Both variables increase together\n",
    "- **Negative correlation**: One increases while other decreases\n",
    "- **Pearson correlation**: Measures linear relationship between variables\n",
    "- **Feature importance**: Identifies which features most influence the target\n",
    "- **Heatmap**: Visual representation of correlation matrix\n",
    "- **Random Forest**: Tree-based model that provides feature importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Create a comprehensive dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "\n",
    "data = {\n",
    "    'Study_Hours': np.random.uniform(1, 10, n_samples),\n",
    "    'Previous_Score': np.random.uniform(50, 95, n_samples),\n",
    "    'Sleep_Hours': np.random.uniform(4, 9, n_samples),\n",
    "    'Attendance': np.random.uniform(60, 100, n_samples),\n",
    "    'Practice_Tests': np.random.randint(0, 20, n_samples)\n",
    "}\n",
    "\n",
    "# Create target variable with intentional relationships\n",
    "data['Final_Score'] = (\n",
    "    5 * data['Study_Hours'] +  # Strong positive correlation\n",
    "    0.3 * data['Previous_Score'] +  # Moderate positive correlation\n",
    "    2 * data['Sleep_Hours'] +  # Weak positive correlation\n",
    "    0.2 * data['Attendance'] +  # Weak positive correlation\n",
    "    1.5 * data['Practice_Tests'] +  # Moderate positive correlation\n",
    "    np.random.normal(0, 5, n_samples)  # Random noise\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head(10))\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# ===========================\n",
    "# 1. CORRELATION ANALYSIS\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Correlation with target variable\n",
    "target_correlation = correlation_matrix['Final_Score'].sort_values(ascending=False)\n",
    "print(\"\\nCorrelation with Final_Score (sorted):\")\n",
    "print(target_correlation)\n",
    "\n",
    "# Statistical significance test for correlations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION SIGNIFICANCE TEST (Pearson)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "features = ['Study_Hours', 'Previous_Score', 'Sleep_Hours', 'Attendance', 'Practice_Tests']\n",
    "for feature in features:\n",
    "    corr, p_value = pearsonr(df[feature], df['Final_Score'])\n",
    "    significance = \"Significant\" if p_value < 0.05 else \"Not Significant\"\n",
    "    print(f\"{feature:20s}: r = {corr:6.3f}, p-value = {p_value:.4f} ({significance})\")\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, fmt='.2f', vmin=-1, vmax=1,\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pairwise scatter plots for top correlated features\n",
    "top_features = target_correlation[1:4].index.tolist()  # Top 3 features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle('Scatter Plots: Top 3 Correlated Features with Final Score', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    axes[idx].scatter(df[feature], df['Final_Score'], alpha=0.6, s=30)\n",
    "    axes[idx].set_xlabel(feature, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Final_Score', fontweight='bold')\n",
    "    \n",
    "    # Add regression line\n",
    "    z = np.polyfit(df[feature], df['Final_Score'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[idx].plot(df[feature], p(df[feature]), \"r--\", linewidth=2, alpha=0.8)\n",
    "    \n",
    "    corr = correlation_matrix.loc[feature, 'Final_Score']\n",
    "    axes[idx].set_title(f'Correlation: {corr:.3f}', fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ===========================\n",
    "# 2. FEATURE IMPORTANCE ANALYSIS\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS (Random Forest)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare data for Random Forest\n",
    "X = df[features]\n",
    "y = df['Final_Score']\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Scores:\")\n",
    "print(feature_importance)\n",
    "print(f\"\\nModel R² Score: {rf_model.score(X, y):.4f}\")\n",
    "\n",
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot for feature importance\n",
    "axes[0].barh(feature_importance['Feature'], feature_importance['Importance'], \n",
    "             color='steelblue', alpha=0.8)\n",
    "axes[0].set_xlabel('Importance Score', fontweight='bold')\n",
    "axes[0].set_title('Feature Importance (Random Forest)', fontweight='bold', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Bar plot for correlation with target\n",
    "target_corr_abs = target_correlation[1:].abs().sort_values(ascending=True)\n",
    "axes[1].barh(target_corr_abs.index, target_corr_abs.values, \n",
    "             color='coral', alpha=0.8)\n",
    "axes[1].set_xlabel('Absolute Correlation', fontweight='bold')\n",
    "axes[1].set_title('Correlation with Final Score', fontweight='bold', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Combined comparison plot\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf_model.feature_importances_,\n",
    "    'Correlation': [abs(correlation_matrix.loc[f, 'Final_Score']) for f in features]\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, comparison_df['Importance'], width, \n",
    "               label='Feature Importance', color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, comparison_df['Correlation'], width, \n",
    "               label='Abs Correlation', color='coral', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Features', fontweight='bold')\n",
    "ax.set_ylabel('Score', fontweight='bold')\n",
    "ax.set_title('Feature Importance vs Correlation Comparison', fontweight='bold', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df['Feature'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Most important feature: {feature_importance.iloc[0]['Feature']}\")\n",
    "print(f\"Most correlated feature: {target_correlation.index[1]}\")\n",
    "print(f\"\\nTop 3 features by importance: {', '.join(feature_importance['Feature'].head(3).tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15: Multiple Subplots - Line, Bar, and Density Plots\n",
    "\n",
    "**Concepts:**\n",
    "- **Subplots**: Multiple plots arranged in a grid layout\n",
    "- **Line plot**: Shows trends and patterns over time or continuous data\n",
    "- **Bar plot**: Compares categorical data or discrete values\n",
    "- **Density plot (KDE)**: Shows probability distribution of continuous variables\n",
    "- **Matplotlib pyplot**: Interface for creating and arranging multiple plots\n",
    "- **Figure and Axes**: Container objects for plots in matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a comprehensive dataset with multiple variables\n",
    "np.random.seed(42)\n",
    "n_points = 100\n",
    "\n",
    "data = {\n",
    "    'Month': pd.date_range(start='2023-01-01', periods=n_points, freq='D'),\n",
    "    'Sales': np.random.normal(5000, 1000, n_points).cumsum() / 10,\n",
    "    'Temperature': 20 + 10 * np.sin(np.linspace(0, 4*np.pi, n_points)) + np.random.normal(0, 2, n_points),\n",
    "    'Customers': np.random.poisson(100, n_points),\n",
    "    'Revenue': np.random.normal(15000, 3000, n_points),\n",
    "    'Profit_Margin': np.random.normal(25, 5, n_points)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add categorical data for bar plots\n",
    "categories = ['Electronics', 'Clothing', 'Food', 'Books', 'Sports']\n",
    "category_data = {\n",
    "    'Category': categories,\n",
    "    'Sales_Volume': [45000, 38000, 42000, 28000, 35000],\n",
    "    'Customer_Count': [1200, 1500, 1800, 900, 1100],\n",
    "    'Avg_Rating': [4.5, 4.2, 4.7, 4.3, 4.4]\n",
    "}\n",
    "df_category = pd.DataFrame(category_data)\n",
    "\n",
    "print(\"Time Series Data Preview:\")\n",
    "print(df.head())\n",
    "print(\"\\nCategorical Data Preview:\")\n",
    "print(df_category)\n",
    "\n",
    "# ===========================\n",
    "# COMPREHENSIVE SUBPLOT LAYOUT\n",
    "# ===========================\n",
    "\n",
    "# Create a 3x3 grid of subplots\n",
    "fig = plt.figure(figsize=(18, 14))\n",
    "fig.suptitle('Comprehensive Data Visualization: Line, Bar, and Density Plots', \n",
    "             fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "# ===========================\n",
    "# ROW 1: LINE PLOTS\n",
    "# ===========================\n",
    "\n",
    "# Line Plot 1: Sales Trend\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "ax1.plot(df['Month'], df['Sales'], color='blue', linewidth=2, marker='o', \n",
    "         markersize=3, alpha=0.7)\n",
    "ax1.set_title('Sales Trend Over Time', fontweight='bold', fontsize=11)\n",
    "ax1.set_xlabel('Date', fontweight='bold')\n",
    "ax1.set_ylabel('Sales ($)', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Line Plot 2: Temperature Variation\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "ax2.plot(df['Month'], df['Temperature'], color='red', linewidth=2, \n",
    "         marker='s', markersize=3, alpha=0.7)\n",
    "ax2.set_title('Temperature Variation', fontweight='bold', fontsize=11)\n",
    "ax2.set_xlabel('Date', fontweight='bold')\n",
    "ax2.set_ylabel('Temperature (°C)', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Line Plot 3: Multiple Variables\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "ax3_twin = ax3.twinx()  # Create secondary y-axis\n",
    "line1 = ax3.plot(df['Month'], df['Customers'], color='green', linewidth=2, \n",
    "                 label='Customers', marker='o', markersize=3, alpha=0.7)\n",
    "line2 = ax3_twin.plot(df['Month'], df['Profit_Margin'], color='orange', linewidth=2, \n",
    "                      label='Profit Margin', marker='^', markersize=3, alpha=0.7)\n",
    "ax3.set_title('Customers vs Profit Margin', fontweight='bold', fontsize=11)\n",
    "ax3.set_xlabel('Date', fontweight='bold')\n",
    "ax3.set_ylabel('Customers', fontweight='bold', color='green')\n",
    "ax3_twin.set_ylabel('Profit Margin (%)', fontweight='bold', color='orange')\n",
    "ax3.tick_params(axis='y', labelcolor='green')\n",
    "ax3_twin.tick_params(axis='y', labelcolor='orange')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ===========================\n",
    "# ROW 2: BAR PLOTS\n",
    "# ===========================\n",
    "\n",
    "# Bar Plot 1: Vertical Bar Chart\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "bars1 = ax4.bar(df_category['Category'], df_category['Sales_Volume'], \n",
    "                color='steelblue', alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "ax4.set_title('Sales Volume by Category', fontweight='bold', fontsize=11)\n",
    "ax4.set_xlabel('Category', fontweight='bold')\n",
    "ax4.set_ylabel('Sales Volume ($)', fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height):,}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Bar Plot 2: Horizontal Bar Chart\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "bars2 = ax5.barh(df_category['Category'], df_category['Customer_Count'], \n",
    "                 color='coral', alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "ax5.set_title('Customer Count by Category', fontweight='bold', fontsize=11)\n",
    "ax5.set_xlabel('Customer Count', fontweight='bold')\n",
    "ax5.set_ylabel('Category', fontweight='bold')\n",
    "ax5.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars2:\n",
    "    width = bar.get_width()\n",
    "    ax5.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "             f'{int(width)}', ha='left', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Bar Plot 3: Grouped Bar Chart\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "x_pos = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "# Normalize data for comparison\n",
    "normalized_sales = df_category['Sales_Volume'] / 1000\n",
    "normalized_customers = df_category['Customer_Count']\n",
    "\n",
    "bars3 = ax6.bar(x_pos - width/2, normalized_sales, width, \n",
    "                label='Sales (×1000)', color='purple', alpha=0.8, edgecolor='black')\n",
    "bars4 = ax6.bar(x_pos + width/2, normalized_customers, width, \n",
    "                label='Customers', color='teal', alpha=0.8, edgecolor='black')\n",
    "\n",
    "ax6.set_title('Grouped Comparison: Sales vs Customers', fontweight='bold', fontsize=11)\n",
    "ax6.set_xlabel('Category', fontweight='bold')\n",
    "ax6.set_ylabel('Count', fontweight='bold')\n",
    "ax6.set_xticks(x_pos)\n",
    "ax6.set_xticklabels(categories, rotation=45)\n",
    "ax6.legend(loc='upper right')\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# ===========================\n",
    "# ROW 3: DENSITY PLOTS\n",
    "# ===========================\n",
    "\n",
    "# Density Plot 1: Single Variable\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "df['Revenue'].plot(kind='density', ax=ax7, color='darkblue', linewidth=3, alpha=0.7)\n",
    "ax7.fill_between(ax7.lines[0].get_xdata(), ax7.lines[0].get_ydata(), \n",
    "                 alpha=0.3, color='lightblue')\n",
    "ax7.set_title('Revenue Distribution (KDE)', fontweight='bold', fontsize=11)\n",
    "ax7.set_xlabel('Revenue ($)', fontweight='bold')\n",
    "ax7.set_ylabel('Density', fontweight='bold')\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# Add mean line\n",
    "mean_revenue = df['Revenue'].mean()\n",
    "ax7.axvline(mean_revenue, color='red', linestyle='--', linewidth=2, label=f'Mean: ${mean_revenue:.0f}')\n",
    "ax7.legend()\n",
    "\n",
    "# Density Plot 2: Comparison of Multiple Variables\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "df['Customers'].plot(kind='density', ax=ax8, color='green', linewidth=2.5, \n",
    "                     alpha=0.7, label='Customers')\n",
    "df['Temperature'].plot(kind='density', ax=ax8, color='red', linewidth=2.5, \n",
    "                       alpha=0.7, label='Temperature')\n",
    "ax8.set_title('Multiple Variables Distribution', fontweight='bold', fontsize=11)\n",
    "ax8.set_xlabel('Value', fontweight='bold')\n",
    "ax8.set_ylabel('Density', fontweight='bold')\n",
    "ax8.legend(loc='upper right')\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# Density Plot 3: Histogram + Density Overlay\n",
    "ax9 = plt.subplot(3, 3, 9)\n",
    "ax9.hist(df['Profit_Margin'], bins=20, density=True, alpha=0.5, \n",
    "         color='gold', edgecolor='black', label='Histogram')\n",
    "df['Profit_Margin'].plot(kind='density', ax=ax9, color='darkred', \n",
    "                         linewidth=3, label='KDE')\n",
    "ax9.set_title('Profit Margin: Histogram + Density', fontweight='bold', fontsize=11)\n",
    "ax9.set_xlabel('Profit Margin (%)', fontweight='bold')\n",
    "ax9.set_ylabel('Density', fontweight='bold')\n",
    "ax9.legend(loc='upper right')\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics text\n",
    "stats_text = f\"Mean: {df['Profit_Margin'].mean():.1f}%\\nStd: {df['Profit_Margin'].std():.1f}%\"\n",
    "ax9.text(0.05, 0.95, stats_text, transform=ax9.transAxes, \n",
    "         fontsize=9, verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "         facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ===========================\n",
    "# ADDITIONAL: FOCUSED VIEW\n",
    "# ===========================\n",
    "\n",
    "# Create a more focused 1x3 layout showing one of each plot type\n",
    "fig2, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "fig2.suptitle('Focused View: Line, Bar, and Density Plots', \n",
    "              fontsize=14, fontweight='bold')\n",
    "\n",
    "# Line plot\n",
    "axes[0].plot(df['Month'][:50], df['Sales'][:50], color='blue', \n",
    "             linewidth=2.5, marker='o', markersize=4)\n",
    "axes[0].set_title('Line Plot: Sales Trend (First 50 Days)', fontweight='bold')\n",
    "axes[0].set_xlabel('Date', fontweight='bold')\n",
    "axes[0].set_ylabel('Sales ($)', fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Bar plot\n",
    "bars = axes[1].bar(df_category['Category'], df_category['Avg_Rating'], \n",
    "                   color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8'],\n",
    "                   alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "axes[1].set_title('Bar Plot: Average Rating by Category', fontweight='bold')\n",
    "axes[1].set_xlabel('Category', fontweight='bold')\n",
    "axes[1].set_ylabel('Average Rating', fontweight='bold')\n",
    "axes[1].set_ylim([0, 5])\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.1f}', ha='center', va='bottom', \n",
    "                 fontsize=10, fontweight='bold')\n",
    "\n",
    "# Density plot\n",
    "axes[2].hist(df['Temperature'], bins=25, density=True, alpha=0.4, \n",
    "             color='orange', edgecolor='black')\n",
    "df['Temperature'].plot(kind='density', ax=axes[2], color='darkred', \n",
    "                       linewidth=3)\n",
    "axes[2].set_title('Density Plot: Temperature Distribution', fontweight='bold')\n",
    "axes[2].set_xlabel('Temperature (°C)', fontweight='bold')\n",
    "axes[2].set_ylabel('Density', fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Add mean and median lines\n",
    "mean_temp = df['Temperature'].mean()\n",
    "median_temp = df['Temperature'].median()\n",
    "axes[2].axvline(mean_temp, color='blue', linestyle='--', linewidth=2, \n",
    "                label=f'Mean: {mean_temp:.1f}°C')\n",
    "axes[2].axvline(median_temp, color='green', linestyle='--', linewidth=2, \n",
    "                label=f'Median: {median_temp:.1f}°C')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PLOT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"Generated 3×3 grid with:\")\n",
    "print(\"  - Row 1: 3 Line plots (trends, comparisons, multiple axes)\")\n",
    "print(\"  - Row 2: 3 Bar plots (vertical, horizontal, grouped)\")\n",
    "print(\"  - Row 3: 3 Density plots (single, multiple, histogram overlay)\")\n",
    "print(\"\\nAdditional focused 1×3 layout created for clearer view.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16: Multiple Linear Regression with Evaluation and Visualization\n",
    "\n",
    "**Concepts:**\n",
    "- **Multiple Linear Regression**: Predicts target using multiple independent variables\n",
    "- **Equation**: y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε\n",
    "- **R² Score**: Proportion of variance explained by model (0 to 1, higher is better)\n",
    "- **MSE (Mean Squared Error)**: Average squared difference between actual and predicted\n",
    "- **RMSE (Root Mean Squared Error)**: Square root of MSE, in same units as target\n",
    "- **Residuals**: Difference between actual and predicted values (errors)\n",
    "- **Residual plot**: Should show random scatter if model is good\n",
    "- **Train-test split**: Divide data to evaluate model on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a comprehensive dataset for regression\n",
    "np.random.seed(42)\n",
    "n_samples = 300\n",
    "\n",
    "# Generate features with realistic relationships\n",
    "data = {\n",
    "    'Study_Hours': np.random.uniform(1, 10, n_samples),\n",
    "    'Previous_Score': np.random.uniform(50, 95, n_samples),\n",
    "    'Sleep_Hours': np.random.uniform(4, 9, n_samples),\n",
    "    'Attendance': np.random.uniform(60, 100, n_samples),\n",
    "    'Practice_Tests': np.random.randint(0, 20, n_samples)\n",
    "}\n",
    "\n",
    "# Create target variable with known coefficients\n",
    "# True equation: Score = 30 + 4*Study + 0.4*Previous + 2*Sleep + 0.1*Attendance + 1*Practice + noise\n",
    "data['Final_Score'] = (\n",
    "    30 +  # Intercept\n",
    "    4.0 * data['Study_Hours'] +\n",
    "    0.4 * data['Previous_Score'] +\n",
    "    2.0 * data['Sleep_Hours'] +\n",
    "    0.1 * data['Attendance'] +\n",
    "    1.0 * data['Practice_Tests'] +\n",
    "    np.random.normal(0, 3, n_samples)  # Random noise\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head(10))\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Prepare features and target\n",
    "feature_columns = ['Study_Hours', 'Previous_Score', 'Sleep_Hours', 'Attendance', 'Practice_Tests']\n",
    "X = df[feature_columns]\n",
    "y = df['Final_Score']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA PREPARATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeatures: {', '.join(feature_columns)}\")\n",
    "print(f\"Target: Final_Score\")\n",
    "\n",
    "# Split data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# ===========================\n",
    "# TRAIN THE MODEL\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING MULTIPLE LINEAR REGRESSION MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "\n",
    "# Display model coefficients\n",
    "print(\"\\nModel Coefficients:\")\n",
    "print(f\"Intercept (β₀): {model.intercept_:.4f}\")\n",
    "print(\"\\nFeature Coefficients:\")\n",
    "for feature, coef in zip(feature_columns, model.coef_):\n",
    "    print(f\"  {feature:20s}: {coef:8.4f}\")\n",
    "\n",
    "# Create regression equation string\n",
    "equation = f\"Final_Score = {model.intercept_:.2f}\"\n",
    "for feature, coef in zip(feature_columns, model.coef_):\n",
    "    equation += f\" + {coef:.2f}×{feature}\"\n",
    "print(f\"\\nRegression Equation:\\n{equation}\")\n",
    "\n",
    "# ===========================\n",
    "# MAKE PREDICTIONS\n",
    "# ===========================\n",
    "\n",
    "# Predictions on training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Predictions on test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# ===========================\n",
    "# EVALUATE THE MODEL\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Training set metrics\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "print(\"\\nTraining Set Performance:\")\n",
    "print(f\"  R² Score:  {train_r2:.4f}\")\n",
    "print(f\"  MSE:       {train_mse:.4f}\")\n",
    "print(f\"  RMSE:      {train_rmse:.4f}\")\n",
    "print(f\"  MAE:       {train_mae:.4f}\")\n",
    "\n",
    "# Testing set metrics\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTesting Set Performance:\")\n",
    "print(f\"  R² Score:  {test_r2:.4f}\")\n",
    "print(f\"  MSE:       {test_mse:.4f}\")\n",
    "print(f\"  RMSE:      {test_rmse:.4f}\")\n",
    "print(f\"  MAE:       {test_mae:.4f}\")\n",
    "\n",
    "# Model interpretation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"The model explains {test_r2*100:.2f}% of the variance in Final Score.\")\n",
    "print(f\"On average, predictions are off by {test_mae:.2f} points.\")\n",
    "print(f\"\\nMost influential feature: {feature_columns[np.argmax(np.abs(model.coef_))]}\")\n",
    "print(f\"Coefficient magnitude: {np.max(np.abs(model.coef_)):.4f}\")\n",
    "\n",
    "# ===========================\n",
    "# RESIDUAL ANALYSIS\n",
    "# ===========================\n",
    "\n",
    "# Calculate residuals\n",
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESIDUAL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Training Residuals - Mean: {train_residuals.mean():.4f}, Std: {train_residuals.std():.4f}\")\n",
    "print(f\"Testing Residuals - Mean: {test_residuals.mean():.4f}, Std: {test_residuals.std():.4f}\")\n",
    "\n",
    "# ===========================\n",
    "# COMPREHENSIVE VISUALIZATION\n",
    "# ===========================\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "fig.suptitle('Multiple Linear Regression: Comprehensive Analysis', \n",
    "             fontsize=18, fontweight='bold', y=0.995)\n",
    "\n",
    "# Plot 1: Actual vs Predicted (Training Set)\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "ax1.scatter(y_train, y_train_pred, alpha=0.5, s=30, color='blue', edgecolors='black', linewidth=0.5)\n",
    "ax1.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "ax1.set_xlabel('Actual Final Score', fontweight='bold')\n",
    "ax1.set_ylabel('Predicted Final Score', fontweight='bold')\n",
    "ax1.set_title(f'Training Set: Actual vs Predicted\\nR² = {train_r2:.4f}', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Actual vs Predicted (Test Set)\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.scatter(y_test, y_test_pred, alpha=0.6, s=40, color='green', edgecolors='black', linewidth=0.5)\n",
    "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "ax2.set_xlabel('Actual Final Score', fontweight='bold')\n",
    "ax2.set_ylabel('Predicted Final Score', fontweight='bold')\n",
    "ax2.set_title(f'Test Set: Actual vs Predicted\\nR² = {test_r2:.4f}', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Coefficients Bar Plot\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "colors = ['red' if c < 0 else 'green' for c in model.coef_]\n",
    "bars = ax3.barh(feature_columns, model.coef_, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax3.axvline(x=0, color='black', linewidth=1)\n",
    "ax3.set_xlabel('Coefficient Value', fontweight='bold')\n",
    "ax3.set_title('Feature Coefficients', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (feature, coef) in enumerate(zip(feature_columns, model.coef_)):\n",
    "    ax3.text(coef, i, f' {coef:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "# Plot 4: Residual Plot (Training Set)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "ax4.scatter(y_train_pred, train_residuals, alpha=0.5, s=30, color='blue', edgecolors='black', linewidth=0.5)\n",
    "ax4.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax4.set_xlabel('Predicted Final Score', fontweight='bold')\n",
    "ax4.set_ylabel('Residuals', fontweight='bold')\n",
    "ax4.set_title('Training Set: Residual Plot', fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Residual Plot (Test Set)\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "ax5.scatter(y_test_pred, test_residuals, alpha=0.6, s=40, color='green', edgecolors='black', linewidth=0.5)\n",
    "ax5.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax5.set_xlabel('Predicted Final Score', fontweight='bold')\n",
    "ax5.set_ylabel('Residuals', fontweight='bold')\n",
    "ax5.set_title('Test Set: Residual Plot', fontweight='bold')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Residual Distribution\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.hist(test_residuals, bins=30, density=True, alpha=0.6, color='orange', edgecolor='black')\n",
    "# Add KDE plot\n",
    "from scipy import stats\n",
    "kde = stats.gaussian_kde(test_residuals)\n",
    "x_range = np.linspace(test_residuals.min(), test_residuals.max(), 100)\n",
    "ax6.plot(x_range, kde(x_range), 'r-', linewidth=2, label='KDE')\n",
    "ax6.axvline(x=0, color='blue', linestyle='--', linewidth=2, label='Zero Error')\n",
    "ax6.set_xlabel('Residual Value', fontweight='bold')\n",
    "ax6.set_ylabel('Density', fontweight='bold')\n",
    "ax6.set_title('Residual Distribution (Test Set)', fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ===========================\n",
    "# ADDITIONAL: REGRESSION LINE PLOTS FOR INDIVIDUAL FEATURES\n",
    "# ===========================\n",
    "\n",
    "fig2, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig2.suptitle('Individual Feature Regression Lines (Single Variable Analysis)', \n",
    "              fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, feature in enumerate(feature_columns):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(X_test[feature], y_test, alpha=0.5, s=30, \n",
    "               color='steelblue', edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    # Fit simple linear regression for visualization\n",
    "    z = np.polyfit(X_test[feature], y_test, 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(X_test[feature].min(), X_test[feature].max(), 100)\n",
    "    ax.plot(x_line, p(x_line), \"r-\", linewidth=2.5, alpha=0.8, label='Regression Line')\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr = np.corrcoef(X_test[feature], y_test)[0, 1]\n",
    "    \n",
    "    ax.set_xlabel(feature, fontweight='bold')\n",
    "    ax.set_ylabel('Final Score', fontweight='bold')\n",
    "    ax.set_title(f'{feature}\\nCorr: {corr:.3f}, Coef: {model.coef_[idx]:.3f}', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide the extra subplot\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ===========================\n",
    "# PREDICTION EXAMPLES\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show some example predictions\n",
    "sample_indices = np.random.choice(X_test.index, 5, replace=False)\n",
    "sample_predictions = pd.DataFrame({\n",
    "    'Study_Hours': X_test.loc[sample_indices, 'Study_Hours'],\n",
    "    'Previous_Score': X_test.loc[sample_indices, 'Previous_Score'],\n",
    "    'Sleep_Hours': X_test.loc[sample_indices, 'Sleep_Hours'],\n",
    "    'Attendance': X_test.loc[sample_indices, 'Attendance'],\n",
    "    'Practice_Tests': X_test.loc[sample_indices, 'Practice_Tests'],\n",
    "    'Actual_Score': y_test.loc[sample_indices],\n",
    "    'Predicted_Score': model.predict(X_test.loc[sample_indices]),\n",
    "    'Error': y_test.loc[sample_indices] - model.predict(X_test.loc[sample_indices])\n",
    "})\n",
    "\n",
    "print(\"\\nSample Predictions from Test Set:\")\n",
    "print(sample_predictions.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model Performance: R² = {test_r2:.4f}, RMSE = {test_rmse:.4f}\")\n",
    "print(f\"The model {'performs well' if test_r2 > 0.8 else 'needs improvement'} on the test set.\")\n",
    "print(f\"Residuals are {'normally distributed' if abs(test_residuals.mean()) < 0.5 else 'not well distributed'}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
